{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "URNHQl4enh_y"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:10px; border:1px solid #ddd; border-radius:8px;\">\n",
        "\n",
        "<h1 style='text-align:center;color:#2c3e50;font-family:Verdana;'><strong>Big Data Science - Fall 2023</strong></h1>\n",
        "\n",
        "<h2 style='text-align:center;color:#3498db;font-family:Verdana;'>Assignment 2: Large Language Models on Protein Sequences</h2>\n",
        "\n",
        "<hr style=\"border-top: 2px solid #3498db; margin-bottom: 20px; margin-top: 20px;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;font-family:Verdana;'>Milestones:</h3>\n",
        "\n",
        "<ol type=\"1\" style='font-family:Verdana;'>\n",
        "    <li><span style='color:#e74c3c;'>Understanding and Implementing Attention Mechanism and BERT Architecture</span></li>\n",
        "    <li><span style='color:#27ae60;'>Fine-tuning Model on 2 Biological Tasks</span></li>\n",
        "    <li><span style='color:#3498db;'>Evaluating Models' Performance with or without pretraining</span></li>\n",
        "</ol>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Sq_vfYC2nh_1"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Submission Deadline: Friday, December 8 at 8:59 P.M.</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'><strong>Notes before you embark on this assignment journey:</strong></p>\n",
        "\n",
        "<ul style='color:#2c3e50;'>\n",
        "    <li><strong>Avoid using built-in libraries</strong> for the core algorithms, strive to build from scratch to strengthen your understanding. If you are allowed to use built-in libraries, you will be notified in the respective sections.\n",
        "    </li>\n",
        "    <li><strong>Collaboration is key</strong> to successful learning, feel free to discuss problems with your peers but ensure your submissions are individual efforts.</li>\n",
        "    <li><strong>The early bird catches the worm!</strong> Start early to allow ample time for exploring, implementing, and seeking help if needed.</li>\n",
        "    <li><strong>Ensure your submission</strong> is a well-documented Jupyter Notebook. Attach your *.ipynb file under Assignment 2 on Canvas.</li>\n",
        "</ul>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DSCy1ybmnh_1"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h2 style='color:#2c3e50;'><strong>Section 1: Problem Definition</strong></h2>\n",
        "\n",
        "<hr style=\"border-top: 2px solid #3498db; margin-bottom: 20px; margin-top: 20px;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'>Goal</h3>\n",
        "<p style='color:#2c3e50;'>Dive into the realm of Molecular Biology and explore how a Language Model (LM) like BERT can be harnessed for protein sequences. </p>\n",
        "\n",
        "<h3 style='color:#2c3e50;'>Introduction to the Problem Domains</h3>\n",
        "<ul style='color:#2c3e50;'>\n",
        "    <li><strong>Proteins</strong> are the workhorses of the body, performing a wide range of functions and biological processes necessary for survival and wellbeing. Understanding their functions can aid in drug discovery, disease diagnosis, and much more.\n",
        "    Proteins are at least 50, and usually more than 100, amino acids in length and composed of multiple peptide subunits. Each protein consists of a linear sequence of amino acids. The sequence of a protein is usually notated as a string of letters including 22 aminoacids and are varied in length from very short to very long! For instance, in NLP we use words and sentences as sequences, similarly in protein modeling we also work with sequences which looks something like this:\n",
        "    <br>​\n",
        "    V​​L​​S​​P​​A​​D​​K​​T​​N​​VK​​A​​A​​W​​G​​K​​V​​G​​A​​H​A​​G​​E​​Y​​G​​A​​E​​A​​L​​E​R​​M​​F​​L​​S​​F​​P​​T​​T​​KT​​Y​​F​​P​​H​​F​​D​​L​​S​​HG​​S​​A​​Q​​V​​K​​G​​H​​G​​K​K​​V​​A​​D​​A​​L​​T​​N​​A​​VA​​H​​V​​D​​D​​M​​P​​N​​A​​L​S​​A​​L​​S​​D​​L​​H​​A​​H​​K​​L​​R​​V​​D​​P​​V​​N​​F​​K​​L​L​​S​​H​​C​​L​​L​​V​​T​​L​​AA​​H​​L​​P​​A​​E​​F​​T​​P​​A​V​​H​​A​​S​​L​​D​​K​​F​​L​​A​​S​​V​​S​​T​​V​​L​​T​​S​​K​​Y​\n",
        "    </br>\n",
        "    <img alt=\"Protein Structure\" src=\"protein.jpeg\" width=\"600\" height=\"400\" align=\"center\"/>\n",
        "    <br>\n",
        "    This sequence belongs to a structure that looks like this: </br>\n",
        "    </li>\n",
        "    <img alt=\"Protein Structure\" src=\"structure.jpg\" width=\"600\" height=\"400\" align=\"center\"/>\n",
        "    <br>\n",
        "    You can find more information about proteins <a href=\"https://www.khanacademy.org/science/biology/macromolecules/proteins-and-amino-acids/v/introduction-to-amino-acids\">here</a>.\n",
        "    </br>\n",
        "    <li><strong>Signal Peptides (SP)</strong> are short sequences of amino acids, typically between 2 and 50 amino acids in length, within a protein that direct the protein to specific locations within or outside the cell. They act like postal addresses, guiding the cellular delivery machinery to transport the protein to its intended location.Once the protein reaches its destination, the signal peptide is often cleaved off by specific enzymes. In the following image, you can see the difference between a peptide and a protein:\n",
        "    <br>\n",
        "    <img alt=\"protein vs peptide\" src=\"peptide.jpeg\" width=\"600\" height=\"400\" align=\"center\"/>\n",
        "    <br>\n",
        "    You can find more information about peptides <a href=\"https://www.cellgs.com/blog/the-difference-between-peptides-and-proteins.html\">here</a>.\n",
        "    <br>\n",
        "    We have a dataset for signal peptides detection in \"data/signal_peptide\" directory. In this dataset, if a protein sequence has a signal peptide, it is labeled as 1, otherwise it is labeled as 0.\n",
        "    </br>\n",
        "    </li>\n",
        "    <li><strong>SCOP</strong>, which stands for Structural Classification of Proteins is a largely manual classification of protein structural domains based on similarities of their structures and amino acid sequences. Predicting the structural class of a protein sequence is another fine-tuning task that we will do in this assignment. For each protein sequence, we have its structural class as its label in \"data/scop\" directory. Labels are categorical and there are 7 classes in total.\n",
        "    </li>\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHP7OMY5nh_2"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Import Libraries and Read Data</strong></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHJHRLpjnh_3"
      },
      "outputs": [],
      "source": [
        "# Please do not change this cell. Run it without changes.\n",
        "# This cell imports the required libraries and sets some parameters.\n",
        "# If you want to change the parameters, you can do so here and mention why you changed them with a comment.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "max_length = 256 # size of the input sequences - if a sequence is longer than this, it will be truncated. If it's shorter, it will be padded.\n",
        "batch_size = 50  # number of sequences that will be given to the model at once\n",
        "epochs = 10     # number of times the model will see the whole training set\n",
        "lr = 1e-2      # learning rate\n",
        "vocab_size = 26  # size of the vocabulary - do not change\n",
        "embed_size = 128 # size of the embeddings - do not change\n",
        "n_heads = 4     # number of attention heads - do not change\n",
        "n_layers = 2   # number of transformer layers - do not change"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRQ0Wul7oN2F",
        "outputId": "f48a9288-e47f-46e0-cc48-9393f867d5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WViS0gt4nh_4"
      },
      "outputs": [],
      "source": [
        "# please don't change this cell. Run it without changes.\n",
        "# this cell is for loading the data needed for the assignment.\n",
        "# pretrain data is downloaded from UniprotKB-SwissProt (https://www.uniprot.org/downloads) latest release.\n",
        "\n",
        "pretrain_data = pd.read_csv('/content/drive/MyDrive/data/pretrain.tsv', sep='\\t')\n",
        "# scop data\n",
        "scop_train_data = pd.read_csv('/content/drive/MyDrive/data/scop/scop.train.csv')\n",
        "scop_test_data = pd.read_csv('/content/drive/MyDrive/data/scop/scop.test.csv')\n",
        "# signal peptide data\n",
        "signalp_train_data = pd.read_csv('/content/drive/MyDrive/data/signal_peptide/signalP_binary.train.csv')\n",
        "signalp_test_data = pd.read_csv('/content/drive/MyDrive/data/signal_peptide/signalP_binary.test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sp_hc2GTnh_4",
        "outputId": "890e8ac2-cdf5-4af3-ad2d-5e89ee023056"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                                seq\n",
              "0  Q65W17  MKPLVIKLGGVLLDTPAAMENLFTALADYQQNFARPLLIVHGGGCL...\n",
              "1  Q12ZI9  MFTILTGSQFGDEGKGKIVDLLSKDYDLVVRFQGGDNAGHTVVVGD...\n",
              "2  O08400  MTRISRSAYAEIYGPTVVGGVGDRVRLADTLLLAEVEKDHTIFGEE...\n",
              "3  O14232  MFGGELDDAFGVFEGKVPKSLKEESKNSQNSQNSQKIKRTLTDKNA...\n",
              "4  Q2FQ95  MNILIVNRYGDPDVEEFSYELEKLLHHHGHHTSIYKENLLGEAPPL..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9ebbcd0-a7a0-4360-a4d8-ec943c6c03db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q65W17</td>\n",
              "      <td>MKPLVIKLGGVLLDTPAAMENLFTALADYQQNFARPLLIVHGGGCL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q12ZI9</td>\n",
              "      <td>MFTILTGSQFGDEGKGKIVDLLSKDYDLVVRFQGGDNAGHTVVVGD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O08400</td>\n",
              "      <td>MTRISRSAYAEIYGPTVVGGVGDRVRLADTLLLAEVEKDHTIFGEE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O14232</td>\n",
              "      <td>MFGGELDDAFGVFEGKVPKSLKEESKNSQNSQNSQKIKRTLTDKNA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q2FQ95</td>\n",
              "      <td>MNILIVNRYGDPDVEEFSYELEKLLHHHGHHTSIYKENLLGEAPPL...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9ebbcd0-a7a0-4360-a4d8-ec943c6c03db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9ebbcd0-a7a0-4360-a4d8-ec943c6c03db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9ebbcd0-a7a0-4360-a4d8-ec943c6c03db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a18df29-bb63-4280-b2bf-66c1457d64a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a18df29-bb63-4280-b2bf-66c1457d64a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a18df29-bb63-4280-b2bf-66c1457d64a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# please don't change this cell. Run it without changes.\n",
        "# this cell is for looking at the pretrain data to get an idea of what it looks like.\n",
        "\n",
        "pretrain_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q-ksKDConh_4",
        "outputId": "b0753878-7676-4720-fae3-4f5924802498"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 seq label\n",
              "0  MSPFTGSAAPTPEWRHLRVEITDGVATVTLARPDKLNALTFEAYAD...     c\n",
              "1  MVVTKLAPDFKAPAVLGNNEVDEHFELSKNLGKNGVILFFWPKDFT...     c\n",
              "2  MKVGIDAGGTLIKIVQEQDNQRTFKTELTKNIDQVVEWLNQQQIEK...     c\n",
              "3  LYKLLILDIDGTLRDEVYGIPESAKHAIRLCQKNHCSVVICTGRSM...     c\n",
              "4  NTSNITFIGGGNMARNIVVGLIANGYDPNRICVTNRSLDKLDFFKE...     c"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a04c352-e4df-4b62-bcc5-806bbf788784\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seq</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MSPFTGSAAPTPEWRHLRVEITDGVATVTLARPDKLNALTFEAYAD...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MVVTKLAPDFKAPAVLGNNEVDEHFELSKNLGKNGVILFFWPKDFT...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MKVGIDAGGTLIKIVQEQDNQRTFKTELTKNIDQVVEWLNQQQIEK...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LYKLLILDIDGTLRDEVYGIPESAKHAIRLCQKNHCSVVICTGRSM...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NTSNITFIGGGNMARNIVVGLIANGYDPNRICVTNRSLDKLDFFKE...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a04c352-e4df-4b62-bcc5-806bbf788784')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a04c352-e4df-4b62-bcc5-806bbf788784 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a04c352-e4df-4b62-bcc5-806bbf788784');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bc0608e0-ea2d-4db6-8ec4-d4560a662ca7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc0608e0-ea2d-4db6-8ec4-d4560a662ca7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bc0608e0-ea2d-4db6-8ec4-d4560a662ca7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# please don't change this cell. Run it without changes.\n",
        "# this cell is for looking at the scop data to get an idea of what it looks like.\n",
        "\n",
        "scop_train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Vzi41-Yknh_4",
        "outputId": "dca42514-7d18-4b82-870a-4f059ebc15c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                                seq\n",
              "0      0  MLGMIRNSLFGSVETWPWQVLSTGGKEDVSYEERACEGGKFATVEV...\n",
              "1      1  MQPAKNLLFSSLLFSSLLFSSAARAASEDGGRGPYVQADLAYAAER...\n",
              "2      0  MDKGEGLRLAATLRQWTRLYGGCHLLLGAVVCSLLAACSSSPPGGV...\n",
              "3      0  MKFIDEAKIEVAAGKGGNGATSFRREKFVPRGGPDGGDGGKGGSVW...\n",
              "4      0  MVAGMLMPRDQLRAIYEVLFREGVMVAKKDRRPRSLHPHVPGVTNL..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58adb62f-6f7e-46f7-a605-ae1c8ca56436\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>MLGMIRNSLFGSVETWPWQVLSTGGKEDVSYEERACEGGKFATVEV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>MQPAKNLLFSSLLFSSLLFSSAARAASEDGGRGPYVQADLAYAAER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>MDKGEGLRLAATLRQWTRLYGGCHLLLGAVVCSLLAACSSSPPGGV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>MKFIDEAKIEVAAGKGGNGATSFRREKFVPRGGPDGGDGGKGGSVW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>MVAGMLMPRDQLRAIYEVLFREGVMVAKKDRRPRSLHPHVPGVTNL...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58adb62f-6f7e-46f7-a605-ae1c8ca56436')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58adb62f-6f7e-46f7-a605-ae1c8ca56436 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58adb62f-6f7e-46f7-a605-ae1c8ca56436');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15b4124b-b8a5-4022-8b17-7d0ed1379bdf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15b4124b-b8a5-4022-8b17-7d0ed1379bdf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15b4124b-b8a5-4022-8b17-7d0ed1379bdf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# please don't change this cell. Run it without changes.\n",
        "# this cell is for looking at the signal peptide data to get an idea of what it looks like.\n",
        "\n",
        "signalp_train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BtCft5XCnh_4"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Section 1. Tokenize Protein Sequences</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>Firstly, you need to have your protein sequences in a format that can be fed into the model. Each amino acid can be represented by a unique token (or ID), similar to how each word is represented by a unique token in NLP tasks. A common representation is to use the single-letter codes for amino acids.</p>\n",
        "<p style='color:#2c3e50;'>We have <b>22 amino acids: \"ACDEFGHIKLMNPQRSTUVWXY\" </b>. There also can be invalid amino acids in protein sequences that we can encode them by <b>'OTHER' </b>token. We need tokens <b>'START'</b>, <b>'END'</b>, and <b>'PAD'</b> for showing starting of the protein sequence, end of protein sequence and padding the protein sequence to a fixed size. <p><b> Do not use predefined tokenizer in keras or tensorflow. You need to implement your own tokenizer for protein sequences.</b></p>\n",
        "</p>\n",
        "<p>\n",
        "    <b>Example (padding to size 32):</b> <br>\n",
        "    <b>Label encoding:</b> {A: 0, C: 1, D: 2, E: 3, F: 4, G: 5, H: 6, I: 7, K: 8, L: 9, M: 10, N: 11, P: 12, Q: 13, R: 14, S: 15, T: 16, V: 17, W: 18, X: 19, Y: 20, OTHER: 21, START: 22, END: 23, PAD: 24} <br>\n",
        "    <b>Input:</b> \"ACDEFGHIKLMNPQRSTUVWXY\" <br>\n",
        "    <b>Output:</b> [22, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24] <br>\n",
        "</p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjRJZb0cnh_5"
      },
      "outputs": [],
      "source": [
        "# fill this function to tokenize a sequence into a list of integers and return the list of integers representing the sequence like the example above.\n",
        "def tokenize_seq(seq, max_length=256):\n",
        "    '''\n",
        "    Tokenize a sequence into a list of integers.\n",
        "    assign each amino acid to a unique integer and add <START>, <END>, <PAD>, <OTHER> tokens to the vocabulary.\n",
        "    <START> token is added to the beginning of each sequence\n",
        "    <END> token is added to the end of each sequence\n",
        "    <PAD> token is used to pad sequences to the same length (max_length)\n",
        "    <OTHER> token is used to represent all amino acids that are not in the vocabulary\n",
        "\n",
        "    Args:\n",
        "        seq (str): protein sequence\n",
        "        max_length (int): maximum length of the sequence\n",
        "    Returns:\n",
        "        tokenized_seq: list of integers representing the sequence\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    amino_acids = \"ACDEFGHIKLMNPQRSTUVWXY\"\n",
        "    vocab = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "    vocab['OTHER'] = len(amino_acids)\n",
        "    vocab['START'] = len(amino_acids) + 1\n",
        "    vocab['END'] = len(amino_acids) + 2\n",
        "    vocab['PAD'] = len(amino_acids) + 3\n",
        "\n",
        "    tokenized_seq = [vocab.get('START')]\n",
        "    for aa in seq:\n",
        "        if aa in vocab:\n",
        "            tokenized_seq.append(vocab[aa])\n",
        "        else:\n",
        "            tokenized_seq.append(vocab['OTHER'])\n",
        "\n",
        "\n",
        "    tokenized_seq.append(vocab['END'])\n",
        "\n",
        "    # Padding the sequence to the maximum length\n",
        "    if len(tokenized_seq) < max_length:\n",
        "        tokenized_seq.extend([vocab['PAD']] * (max_length - len(tokenized_seq)))\n",
        "    else:\n",
        "        tokenized_seq = tokenized_seq[:max_length]\n",
        "\n",
        "    return tokenized_seq\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSJuhykIgrMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1jjpcI4nh_5"
      },
      "outputs": [],
      "source": [
        "# please don't change this cell and don't add any print statements to this cell. Run it without changes.\n",
        "# this cell is tokenizing the pretrain data and converting it to numpy array.\n",
        "\n",
        "pretrain_seq = [tokenize_seq(seq) for seq in pretrain_data['seq']]\n",
        "pretrain_seq = np.array(pretrain_seq)\n",
        "pretrain_seq = pretrain_seq.astype(np.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgjPPqeonh_5"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h2 style='color:#2c3e50;'><strong>Section 2: Pretrain a Language Model</strong></h2>\n",
        "\n",
        "<hr style=\"border-top: 2px solid #3498db; margin-bottom: 20px; margin-top: 20px;\">\n",
        "\n",
        "<ul style='color:#2c3e50;'>\n",
        "    <li>Implement the attention mechanism</li>\n",
        "    <li>Implement BERT architecture</li>\n",
        "    <li>Train the model by the protein sequences.</li>\n",
        "</ul>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WHwWHv48nh_5"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Task 2.1: Implementing the Self-Attention Class</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>Implement a multihead self-attention mechanism that will be the building block for BERT model.</p>\n",
        "\n",
        "<p style='color:#2c3e50;'><strong>Multihead self-attention</strong> is a mechanism at the heart of Transformer models, which are widely used for various natural language processing tasks. It allows the model to focus on different positions of the input sequence simultaneously when producing an output. Here's a simplified explanation:\n",
        "<p style='color:#2c3e50;'>\n",
        "<strong>Self-Attention:</strong> This component allows each position in a sequence to attend to all positions within the same sequence when computing the representation of itself. It helps the model capture context from the entire sequence.\n",
        "<p style='color:#2c3e50;'>\n",
        "<strong>Multihead:</strong> The 'multihead' part means that the self-attention process is duplicated multiple times (each 'head' being one instance). Each head attends to information from different representational spaces at different positions. This means that instead of having a single set of attention weights for each position, you have multiple sets, allowing the model to capture a diverse range of information which enhances its learning capacity for complex patterns in data.\n",
        "<p style='color:#2c3e50;'>\n",
        "<strong>Mechanism Overview:</strong> In practice, for each head, the input sequence is linearly transformed to a set of queries, keys, and values using learned weights. Then, the attention scores are computed by a <b>scaled dot-product of queries and keys</b>, which are used to weight the values. The outputs of each head are concatenated and once again linearly transformed to produce the final output. </p>\n",
        "<img alt=\"Multihead Self-Attention\" src=\"attention.jpg\" width=\"600\" height=\"400\" align=\"center\"/>\n",
        "<p> You can read more about attention mechanism <a href=\"https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853\">here</a>.</p>\n",
        "<p>\n",
        "An attention mask in the context of self-attention mechanisms is used to prevent certain positions from being attended to. For instance, when processing sequences of different lengths, padding tokens are added to achieve uniformity in length. An attention mask can be applied to ensure that these padding tokens do not influence the model's output. It's also used to enforce causality in sequence-to-sequence tasks, ensuring that predictions for a certain position can't depend on future positions. Although it is necessary to use attention masks in some cases, we will not use them in this assignment.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MultiSelfAttentionHead(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads=4, key_dim=64, **kwargs):\n",
        "        super(MultiSelfAttentionHead, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.scale = key_dim ** -0.5\n",
        "        self.depth = key_dim // num_heads\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # split the last dimension into (num_heads, depth) and transpose the result such\n",
        "        # that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        # Fill variable x\n",
        "        input_shape=x.shape\n",
        "        #x = tf.reshape(x, (batch_size,self.num_heads,input_shape[1], self.depth))\n",
        "        x=tf.reshape(x, (tf.shape(x)[0], -1, self.num_heads, self.depth))\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def build(self, inputs_s):\n",
        "        # Create trainable weight matrices for Q, K, V, and the final output\n",
        "\n",
        "        #self.wq = tf.Variable(tf.random.normal((inputs_s[-1], self.key_dim)), dtype=tf.float32)\n",
        "        #print(self.wq.shape)\n",
        "        self.wq= tf.keras.layers.Dense(units=self.key_dim , use_bias=True)\n",
        "        self.wk = tf.keras.layers.Dense(units=self.key_dim , use_bias=True)\n",
        "        self.wv= tf.keras.layers.Dense(units=self.key_dim , use_bias=True)\n",
        "        self.wo=tf.keras.layers.Dense(units=inputs_s[-1], use_bias=True)\n",
        "        assert self.key_dim % self.num_heads == 0, \"key_dim must be divisible by num_heads\"\n",
        "        super(MultiSelfAttentionHead, self).build(inputs_s)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        # Linear projections of Q, K, V (Gray Linear layers in the begining of the right image above)\n",
        "        # Fill variables query, key, value\n",
        "        #q = tf.matmul(inputs, self.wq)  # (batch_size, seq_len, key_dim)\n",
        "\n",
        "        q=self.wq(inputs)\n",
        "        k = self.wk(inputs)  # (batch_size, seq_len, key_dim)\n",
        "        v = self.wv(inputs) # (batch_size, seq_len, key_dim)\n",
        "\n",
        "        # Split the heads using split_heads function\n",
        "        # Fill variables query, key, value\n",
        "\n",
        "\n",
        "        query = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n",
        "        key = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_k, depth)\n",
        "        value = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # Linear projection between Q and K (in the left image above)\n",
        "        # Fill variable linear_qk\n",
        "\n",
        "        linear_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "\n",
        "        # Scale Linear projection between Q and K using self.scale (in the left image above)\n",
        "        # Fill variable scaled_linear_qk\n",
        "\n",
        "        scaled_linear_qk = linear_qk * self.scale\n",
        "\n",
        "\n",
        "        # Apply softmax to the last axis of scaled_linear_qk\n",
        "        # Fill variable attention_weights\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_linear_qk, axis=-1)\n",
        "\n",
        "\n",
        "        # Matmul of attention_weights and value (in the left image above)\n",
        "        # Fill variable context\n",
        "\n",
        "        context = tf.matmul(attention_weights, value)# (batch_size, num_heads, seq_len_q, depth)\n",
        "\n",
        "\n",
        "        # 'Concatenate' heads (in the right image above) using tf.transpose and tf.reshape\n",
        "        # Fill variable context\n",
        "\n",
        "\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])\n",
        "\n",
        "        context = tf.reshape(context, (batch_size, -1, self.key_dim))\n",
        "\n",
        "\n",
        "        # Final linear projection (Gray Linear layer in the end of the right image above) between context and self.wo\n",
        "        # Fill variable outputs\n",
        "\n",
        "        outputs = self.wo(context)\n",
        "\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "_BuPtLeRWn2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Bu91OYCLnh_6"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Task 2.2: Implementing the BERT Architecture</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>Implement BERT architecture.</p>\n",
        "<p> You can read more about BERT in the original <a href=\"https://arxiv.org/pdf/1810.04805.pdf\">paper</a>.</p>\n",
        "<p>\n",
        "BERT is based on encoder transformer. Encoder consists of multi-head attention and feed-forward neural network. In original Transformers paper <a href=\"https://arxiv.org/pdf/1706.03762.pdf\">Attention Is All You Need</a> and in this assignment, the stack of identical encoder layers is used.\n",
        "</p>\n",
        "<img alt=\"Encoder transformer\" src=\"encoder.png\" width=\"300\" height=\"400\" align=\"center\"/>\n",
        "<p> In BERT function, you need to implement the following steps:</p>\n",
        "<p>\n",
        "<strong>Inputs:</strong> The function takes several parameters like vocabulary size, embedding size, number of layers, attention heads, and maximum sequence length. Additionally, it expects an input sequence and an attention mask when called.\n",
        "<p>\n",
        "<strong>Embedding Layer:</strong> The model begins by mapping the input sequence of tokens to vectors using an embedding layer.\n",
        "<p>\n",
        "<strong>Encoder Layers:</strong> It then passes the embedded input through a series of identical layers. Each layer consists of:\n",
        "1. A multi-head self-attention mechanism that allows the model to capture different aspects of the data. The attention output is combined with the original embeddings using a residual connection followed by layer normalization.\n",
        "2. A feed-forward neural network (FFN) with two dense layers is applied after each attention mechanism, also followed by a residual connection and layer normalization.\n",
        "<p>\n",
        "<strong>Outputs:</strong> After processing the input through the specified number of encoder layers, the function applies a dense layer with softmax activation to produce a probability distribution over the vocabulary for each position in the input sequence.\n",
        "<p>\n",
        "<strong>Model Creation:</strong> Finally, it encapsulates the complete architecture within a Keras Model object, which can be compiled and trained.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hcs1lmrbWyXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, Dense\n",
        "from tensorflow.keras.layers import LayerNormalization, Dropout, Flatten\n",
        "\n",
        "def BERT(vocab_size, embed_size=128, n_layers=2, n_heads=4, max_length=256):\n",
        "    '''\n",
        "    BERT model.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): vocabulary size (number of tokens)\n",
        "        embed_size (int): embedding size (dimension of the token embedding)\n",
        "        n_layers (int): number of layers in the encoder stack\n",
        "        n_heads (int): number of attention heads in each multi-head attention layer\n",
        "        max_length (int): maximum length of the sequence\n",
        "\n",
        "    Inputs:\n",
        "        input_seq (tf.Tensor): input tensor with shape [Batch_size, max_length];\n",
        "            No positional encoding is added to the input sequence\n",
        "\n",
        "    Outputs:\n",
        "        output (tf.Tensor): output tensor with shape [Batch_size, max_length, vocab_size]\n",
        "        return model (tf.keras.Model): BERT model\n",
        "\n",
        "    Model Architecture (as described above):\n",
        "        1. Input Layer\n",
        "        2. Embedding Layer\n",
        "        3. Multi-Head Self-Attention Layers\n",
        "        4. Add and Norm Layer\n",
        "        5. Feed-Forward Layers\n",
        "        6. Add and Norm Layer\n",
        "        7. Dense Layer (vocab_size) with softmax activation\n",
        "        Steps 3-6 are repeated n_layers times.\n",
        "    '''\n",
        "\n",
        "    # Input layer\n",
        "    #inputs = Input(shape=(max_length,), dtype=tf.int32, name='input_seq')\n",
        "\n",
        "    # Embedding layer\n",
        "    input= tf.keras.Input(shape=(max_length,), batch_size=50, name='input_seq')\n",
        "\n",
        "    #batch =Input(shape=(max_length,), dtype=tf.float32, name='input_seq')\n",
        "    embedding = Embedding(input_dim=vocab_size, output_dim=embed_size)(input)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Multi-Head Self-Attention Layers (Repeat n_layers times)\n",
        "    for _ in range(n_layers):\n",
        "\n",
        "        attention_layer = MultiSelfAttentionHead(num_heads=4, key_dim=64)\n",
        "        attention = attention_layer(embedding)\n",
        "\n",
        "        add_norm_1 = LayerNormalization(epsilon=1e-6)(embedding + attention)\n",
        "\n",
        "        feed_forward1 = Dense(units=embed_size, activation='relu')(add_norm_1)\n",
        "        feed_forward2 = Dense(units=embed_size, use_bias=True)(feed_forward1)\n",
        "        add_norm_2 = LayerNormalization(epsilon=1e-6)(add_norm_1 + feed_forward2)\n",
        "        embedding = add_norm_2\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "\n",
        "    output = Dense(units=vocab_size, activation='softmax')(embedding)\n",
        "\n",
        "    # Build model\n",
        "    model = tf.keras.Model(inputs=input, outputs=output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "SOCTGXxNWyoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_gwT2Rbnh_6"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "<h3 style='color:#2c3e50;'><strong>Section 3: Implementing Noised Tokens Prediction (NTP)</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>In previous cell, you implemented BERT architecture. In main version of BERT, we use Masked Language Models (MLMs) and Next Sentence Prediction (NSP) as pretraining tasks.\n",
        "<p>\n",
        "In Masked Language Modeling, random tokens in a sentence are replaced with a special token (e.g., \"[MASK]\"). The model's task is to predict the original token based on the context provided by the other non-masked tokens in the input. This allows the model to develop a deep understanding of language structure and word relationships.\n",
        "<p>\n",
        "The Next Sentence Prediction task involves presenting the model with two sentences and requiring it to predict whether the second sentence follows the first in the original text. This helps the model to learn relationships between consecutive sentences, which is important for understanding the coherence and flow of paragraphs.\n",
        "<br>\n",
        "You can read more about BERT pretraining tasks in the original <a href=\"https://arxiv.org/pdf/1810.04805.pdf\">paper</a> or <a href=\"https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\">here</a>.\n",
        "<p>\n",
        "In this assignment, however, we want to define a new task called <b>Noised Tokens Prediction (NTP)</b> and use it instead of MLMs and NSP tasks. In this task, we randomlely change tokens in the input sequence to get a noisy sequence to get it to the model and want the model to predict the original sequence. For example, if the input sequence is \"ABCDEF\", with some probability, it is changed into \"ABXDEF\"; so the input of the model would be \"ABXDEF\" and the output should be \"ABCDEF\". You need to implement this task in the following cell. Feel free to use numpy library for randomization.</p>\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def noise_tokens(encoded_seqs, p_token_noise=0.15, n_tokens=vocab_size):\n",
        "    '''\n",
        "    Add noise to the input sequences.\n",
        "    Args:\n",
        "        encoded_seqs (np.array): encoded sequences with shape [Batch_size, max_length]\n",
        "        p_token_noise (float): probability of adding noise to each token\n",
        "        n_tokens (int): number of tokens in the vocabulary\n",
        "    Returns:\n",
        "        noisy_encoded_seqs (np.array): encoded sequences with noise with shape [Batch_size, max_length]\n",
        "        original_seqs (np.array): original encoded sequences with shape [Batch_size, max_length]\n",
        "    '''\n",
        "    # Copy the original sequences to avoid modifying the input\n",
        "    noisy_encoded_seqs = np.copy(encoded_seqs)\n",
        "\n",
        "    # Create a mask with True values based on the probability\n",
        "    mask = np.random.rand(*encoded_seqs.shape) < p_token_noise\n",
        "\n",
        "    # Generate random noisy tokens for the masked positions\n",
        "    noisy_tokens = np.random.randint(0, n_tokens, size=mask.sum())\n",
        "\n",
        "    # Apply the noise to the corresponding positions in the sequences\n",
        "    noisy_encoded_seqs[mask] = noisy_tokens\n",
        "\n",
        "    return noisy_encoded_seqs, encoded_seqs\n",
        "\n",
        "# Example usage:\n",
        "# Replace 'encoded_seqs' with your actual encoded sequences\n",
        "# Specify the appropriate values for 'p_token_noise' and 'n_tokens'\n",
        "# noisy_seqs, original_seqs = noise_tokens(encoded_seqs, p_token_noise=0.15, n_tokens=vocab_size)\n"
      ],
      "metadata": {
        "id": "3yTS97-19U3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a840WEOnh_7"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Section 4: Pretraining the Model</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>Create an instance of your BERT model and train it on pretrain data.</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def pretraining(model, noisy_pretrain_seq, pretrain_seq, epochs, batch_size, lr=1e-2):\n",
        "    '''\n",
        "    Pretrain the model: Input is noised sequences and output is original sequences.\n",
        "    Args:\n",
        "        model (tf.keras.Model): BERT model\n",
        "        noisy_pretrain_seq (np.array): encoded sequences with noise with shape [Batch_size, max_length]\n",
        "        pretrain_seq (np.array): original encoded sequences with shape [Batch_size, max_length]\n",
        "        epochs (int): number of epochs\n",
        "        batch_size (int): batch size\n",
        "        lr (float): learning rate\n",
        "    Returns:\n",
        "        model (tf.keras.Model): pretrained BERT model\n",
        "    '''\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                         loss=loss_fn,\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    #model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "    original_sequences_one_hot = tf.keras.utils.to_categorical(pretrain_seq, num_classes=vocab_size)\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "\n",
        "\n",
        "    model.fit(noisy_pretrain_seq, original_sequences_one_hot, epochs=epochs, batch_size=50)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "# Replace 'YourBERTModel' with the actual class or instance of your BERT model\n",
        "# Replace 'noisy_pretrain_seq' and 'pretrain_seq' with your actual noisy and original sequences\n",
        "# Specify the appropriate values for 'epochs', 'batch_size', and 'lr'\n",
        "# model = pretraining(YourBERTModel, noisy_pretrain_seq, pretrain_seq, epochs=10, batch_size=32, lr=1e-3)\n"
      ],
      "metadata": {
        "id": "5gMjCd7hSoWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wtRRrWofJdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# please don't change this cell and don't add any print statements to this cell. Run it without changes.\n",
        "# this cell is for training the model on the pretrain data.\n",
        "\n",
        "model = BERT(vocab_size=vocab_size, embed_size=128, n_layers=2, n_heads=4, max_length=256)\n",
        "model.summary()\n",
        "\n",
        "noisy_pretrain_seq, pretrain_seq = noise_tokens(pretrain_seq)\n",
        "\n",
        "pretrained_model = pretraining(model, noisy_pretrain_seq, pretrain_seq, epochs=1, batch_size=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLoYDmHaiZMT",
        "outputId": "89f0421a-bc64-4fec-96cd-4b306488cd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_seq (InputLayer)      [(50, 256)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (50, 256, 128)               3328      ['input_seq[0][0]']           \n",
            "                                                                                                  \n",
            " multi_self_attention_head   (50, 256, 128)               33088     ['embedding[0][0]']           \n",
            " (MultiSelfAttentionHead)                                                                         \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (50, 256, 128)               0         ['embedding[0][0]',           \n",
            " Lambda)                                                             'multi_self_attention_head[0]\n",
            "                                                                    [0]']                         \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (50, 256, 128)               256       ['tf.__operators__.add[0][0]']\n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense (Dense)               (50, 256, 128)               16512     ['layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (50, 256, 128)               16512     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (50, 256, 128)               0         ['layer_normalization[0][0]', \n",
            " OpLambda)                                                           'dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (50, 256, 128)               256       ['tf.__operators__.add_1[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " multi_self_attention_head_  (50, 256, 128)               33088     ['layer_normalization_1[0][0]'\n",
            " 1 (MultiSelfAttentionHead)                                         ]                             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (50, 256, 128)               0         ['layer_normalization_1[0][0]'\n",
            " OpLambda)                                                          , 'multi_self_attention_head_1\n",
            "                                                                    [0][0]']                      \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (50, 256, 128)               256       ['tf.__operators__.add_2[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (50, 256, 128)               16512     ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (50, 256, 128)               16512     ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (50, 256, 128)               0         ['layer_normalization_2[0][0]'\n",
            " OpLambda)                                                          , 'dense_3[0][0]']            \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (50, 256, 128)               256       ['tf.__operators__.add_3[0][0]\n",
            " erNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (50, 256, 26)                3354      ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 139930 (546.60 KB)\n",
            "Trainable params: 139930 (546.60 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "600/600 [==============================] - 541s 891ms/step - loss: 0.7538 - accuracy: 0.8549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.save_weights(\"model_pretrained.weights.h5\")"
      ],
      "metadata": {
        "id": "eqell7h0ep7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# please don't change this cell and don't add any print statements to this cell. Run it without changes.\n",
        "# this cell is for saving the pretrained model.\n",
        "\n",
        "if not os.path.exists('model'):\n",
        "    os.makedirs('model')\n",
        "pretrained_model.save_weights('model/model_pretrained.h5')"
      ],
      "metadata": {
        "id": "ArioPj6pyE8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "oJQV1_vfnh_7"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h2 style='color:#2c3e50;'><strong>Section 5: Fine-tuning Large Language Models</strong></h2>\n",
        "\n",
        "<hr style=\"border-top: 2px solid #3498db; margin-bottom: 20px; margin-top: 20px;\">\n",
        "\n",
        "<ul style='color:#2c3e50;'>\n",
        "    <li>Prepare the data for fine-tuning: Tokenize protein sequences in both train and test data of signal peptides detection and structure classification tasks. Then, convert them to numpy arrays. (like what you did in section 1 for pretraining data)</li>\n",
        "    <li>Fine-tune the model on tasks signal peptides detection (binary classification) and structure classification (multi-class classification). By fine-tuning, we mean the process of adjusting the parameters of the pre-trained model to suit a specific task or dataset. Through this process, we can enhance the model's ability to perform a specialized task more accurately.</li>\n",
        "    <li>For each task, you need to call the pretrained model and add a classification layer on top of it. Then, you need to freeze the pretrained model and train the classification layer for 10 epochs. After that, you need to unfreeze the pretrained model and train the whole model for 5 epochs.</li>\n",
        "    </li>\n",
        "</ul>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9s9UxQvnh_7"
      },
      "outputs": [],
      "source": [
        "# please don't change this cell and don't add any print statements to this cell. Run it without changes.\n",
        "# this cell is for connecting the layers of the pretrained model to the layers of the finetuned model.\n",
        "# the output of the last layer of the pretrained model is considered as the input of the finetuned model.\n",
        "\n",
        "def concat_layers_for_finetuning(model):\n",
        "    # Create a list to hold the layers to be concatenated\n",
        "\n",
        "    return tf.keras.Model(inputs=model.inputs, outputs=model.layers[-1].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXlf7bT-nh_7"
      },
      "outputs": [],
      "source": [
        "# please don't change this cell\n",
        "# this cell is for loading the pretrained model and keep the output of the last layer to be used for finetuning.\n",
        "\n",
        "model_SP = BERT(vocab_size=vocab_size, embed_size=embed_size, n_layers=n_layers, n_heads=n_heads, max_length=max_length)\n",
        "model_SP.load_weights((\"model_pretrained.weights.h5\"))\n",
        "concat_model_SP = concat_layers_for_finetuning(model_SP)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill this function to fine-tune the concat_model_SP on peptide detection task (binary classification)\n",
        "\n",
        "'''\n",
        "Fine-tune the model on peptide detection task.\n",
        "Parameters:\n",
        "    epochs (int): number of epochs\n",
        "    batch_size (int): batch size\n",
        "    lr (float): learning rate\n",
        "    n_classes (int): number of classes\n",
        "\n",
        "What you need to do in this cell:\n",
        "    1. Tokenize the sequences in scop_train_data\n",
        "    2. Make the labels in scop_train_data as a numpy array\n",
        "    3. Make the layers of the concat_model_SP non-trainable\n",
        "    4. Add a dense layer with a proper activation to the end of the concat_model_SP\n",
        "    5. Define a new model with the input of concat_model_SP and the output of the dense layer\n",
        "    6. Define the loss function and optimizer\n",
        "    7. Compile the model with the loss function and optimizer\n",
        "    8. Fit the model on the training data for 10 epochs\n",
        "    9. Make all layers of the model trainable\n",
        "    10. Fit the model on the training data for 5 epochs\n",
        "    11. Save the new model in the model directory with the name model_finetuned_SP.h5\n",
        "    '''\n",
        "\n",
        "# YOUR CODE HERE\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming 'model_directory' already exists\n",
        "\n",
        "\n",
        "def fine_tune_peptide_detection(concat_model_SP, signalp_train_data, epochs=15, batch_size=50, lr=0.001, n_classes=2):\n",
        "    # Tokenize sequences\n",
        "\n",
        "\n",
        "    signalp_train_seq = [tokenize_seq(seq) for seq in  signalp_train_data['seq']]\n",
        "    signalp_train_seq  = np.array(signalp_train_seq )\n",
        "    X_train= signalp_train_seq .astype(np.int32)\n",
        "\n",
        "    y_train = (signalp_train_data['label'])\n",
        "    y_train = tf.keras.utils.to_categorical( y_train, num_classes=n_classes)\n",
        "\n",
        "\n",
        "    # Make layers of concat_model_SP non-trainable\n",
        "    for layer in concat_model_SP.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    output_layer = Dense(n_classes, activation='sigmoid')(concat_model_SP.layers[-1].output[:,0])\n",
        "\n",
        "\n",
        "    # Define a new model\n",
        "\n",
        "    model = Model(inputs=concat_model_SP.input, outputs= output_layer)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    loss_function =BinaryCrossentropy()\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model on the training data for 10 epochs\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=batch_size)\n",
        "    # Make all layers of the model trainable\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # Fit the model on the training data for additional 5 epochs\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=batch_size)\n",
        "\n",
        "    # Save the entire model\n",
        "    model.save_weights(\"model_finetuned_SP.weights.h5\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Call the function with the provided parameters\n",
        "Finetune_SP=fine_tune_peptide_detection(concat_model_SP, signalp_train_data, epochs=15, batch_size=50, lr=0.001, n_classes=2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxH53bP0BKMV",
        "outputId": "6bd5bb9b-b446-45c8-e89a-18110890c095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "333/333 [==============================] - 101s 293ms/step - loss: 0.5484 - accuracy: 0.8375\n",
            "Epoch 2/10\n",
            "333/333 [==============================] - 100s 299ms/step - loss: 0.4752 - accuracy: 0.8375\n",
            "Epoch 3/10\n",
            "333/333 [==============================] - 98s 293ms/step - loss: 0.4519 - accuracy: 0.8375\n",
            "Epoch 4/10\n",
            "333/333 [==============================] - 99s 297ms/step - loss: 0.4455 - accuracy: 0.8375\n",
            "Epoch 5/10\n",
            "333/333 [==============================] - 100s 299ms/step - loss: 0.4441 - accuracy: 0.8375\n",
            "Epoch 6/10\n",
            "333/333 [==============================] - 100s 299ms/step - loss: 0.4439 - accuracy: 0.8375\n",
            "Epoch 7/10\n",
            "333/333 [==============================] - 99s 299ms/step - loss: 0.4438 - accuracy: 0.8375\n",
            "Epoch 8/10\n",
            "333/333 [==============================] - 97s 292ms/step - loss: 0.4438 - accuracy: 0.8375\n",
            "Epoch 9/10\n",
            "333/333 [==============================] - 97s 291ms/step - loss: 0.4437 - accuracy: 0.8375\n",
            "Epoch 10/10\n",
            "333/333 [==============================] - 97s 292ms/step - loss: 0.4438 - accuracy: 0.8375\n",
            "Epoch 1/5\n",
            "333/333 [==============================] - 97s 291ms/step - loss: 0.4437 - accuracy: 0.8375\n",
            "Epoch 2/5\n",
            "333/333 [==============================] - 97s 291ms/step - loss: 0.4437 - accuracy: 0.8375\n",
            "Epoch 3/5\n",
            "333/333 [==============================] - 97s 291ms/step - loss: 0.4436 - accuracy: 0.8375\n",
            "Epoch 4/5\n",
            "333/333 [==============================] - 97s 290ms/step - loss: 0.4436 - accuracy: 0.8375\n",
            "Epoch 5/5\n",
            "333/333 [==============================] - 97s 290ms/step - loss: 0.4436 - accuracy: 0.8375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nRARh8knh_8"
      },
      "outputs": [],
      "source": [
        "# please don't change this cell\n",
        "# this cell is for loading the pretrained model and keep the output of the last layer to be used for finetuning.\n",
        "\n",
        "model_SC = BERT(vocab_size=vocab_size, embed_size=128, n_layers=2, n_heads=4, max_length=max_length)\n",
        "model_SC.load_weights((\"model_pretrained.weights.h5\"))\n",
        "model_concat_SC = concat_layers_for_finetuning(model_SC)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill this function to fine-tune the model_concat_SC on structure classification task (multi-class classification)\n",
        "'''\n",
        "Fine-tune the model on peptide detection task.\n",
        "Parameters:\n",
        "    epochs (int): number of epochs\n",
        "    batch_size (int): batch size\n",
        "    lr (float): learning rate\n",
        "    n_classes (int): number of classes\n",
        "\n",
        "What you need to do in this cell:\n",
        "    1. Tokenize the sequences in scop_train_data\n",
        "    2. Make the labels in scop_train_data as a numpy array\n",
        "    3. Make the layers of the model_concat_SC non-trainable\n",
        "    4. Add a dense layer with a proper activation to the end of the model_concat_SC\n",
        "    5. Define a new model with the input of model_concat_SC and the output of the dense layer\n",
        "    6. Define the loss function and optimizer\n",
        "    7. Compile the model with the loss function and optimizer\n",
        "    8. Fit the model on the training data for 10 epochs\n",
        "    9. Make all layers of the model trainable\n",
        "    10. Fit the model on the training data for 5 epochs\n",
        "    11. Save the new model in the model directory with the name model_finetuned_SC.h5\n",
        "'''\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# Fill this function to fine-tune the concat_model_SP on peptide detection task (binary classification)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming 'model_directory' already exists\n",
        "\n",
        "\n",
        "def fine_tune_structural_classification(concat_model_SC, scop_train_data, epochs=15, batch_size=50, lr=0.001, n_classes=2):\n",
        "    # Tokenize sequences\n",
        "\n",
        "\n",
        "    scop_train_seq = [tokenize_seq(seq) for seq in  scop_train_data['seq']]\n",
        "    scop_train_seq = np.array(scop_train_seq)\n",
        "    X_train= scop_train_seq.astype(np.int32)\n",
        "\n",
        "    y_train = (scop_train_data['label'])\n",
        "    label_mapping = {'a': 0, 'b': 1, 'c': 2,'d': 3, 'e': 4, 'f': 5}\n",
        "    y_train = y_train.map(label_mapping)\n",
        "    y_train = y_train.fillna(0)\n",
        "    y_train = to_categorical(y_train, num_classes=6)\n",
        "\n",
        "\n",
        "    # Make layers of concat_model_SC non-trainable\n",
        "    for layer in concat_model_SC.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add a dense layer to the end of concat_model_SP\n",
        "    output_layer = Dense(n_classes, activation='sigmoid')(concat_model_SC.layers[-1].output[:,0])\n",
        "    # Define a new model\n",
        "    model = Model(inputs=concat_model_SC.input, outputs= output_layer)\n",
        "\n",
        "    #print(output_layer.shape,\"opt\")\n",
        "    # Define loss function and optimizer\n",
        "    loss_function =CategoricalCrossentropy()\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model on the training data for 10 epochs\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=batch_size)\n",
        "    # Make all layers of the model trainable\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # Fit the model on the training data for additional 5 epochs\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=batch_size)\n",
        "\n",
        "    # Save the entire model\n",
        "    model.save_weights(\"model_finetuned_SC.weights.h5\")\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Call the function with the provided parameters\n",
        "Model_finetune_SC=fine_tune_structural_classification(model_concat_SC , scop_train_data, epochs=15, batch_size=50, lr=0.001, n_classes=6)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuY2yCs-UlcD",
        "outputId": "b2686609-6fb8-42a4-a195-7c8ac1a4a8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "314/314 [==============================] - 99s 308ms/step - loss: 1.6809 - accuracy: 0.2807\n",
            "Epoch 2/10\n",
            "314/314 [==============================] - 95s 301ms/step - loss: 1.5427 - accuracy: 0.3807\n",
            "Epoch 3/10\n",
            "314/314 [==============================] - 93s 295ms/step - loss: 1.4836 - accuracy: 0.3803\n",
            "Epoch 4/10\n",
            "314/314 [==============================] - 93s 298ms/step - loss: 1.4525 - accuracy: 0.3964\n",
            "Epoch 5/10\n",
            "314/314 [==============================] - 111s 353ms/step - loss: 1.4325 - accuracy: 0.4122\n",
            "Epoch 6/10\n",
            "314/314 [==============================] - 93s 297ms/step - loss: 1.4178 - accuracy: 0.4152\n",
            "Epoch 7/10\n",
            "314/314 [==============================] - 132s 420ms/step - loss: 1.4060 - accuracy: 0.4216\n",
            "Epoch 8/10\n",
            "314/314 [==============================] - 100s 319ms/step - loss: 1.3961 - accuracy: 0.4254\n",
            "Epoch 9/10\n",
            "314/314 [==============================] - 130s 415ms/step - loss: 1.3873 - accuracy: 0.4268\n",
            "Epoch 10/10\n",
            "314/314 [==============================] - 113s 360ms/step - loss: 1.3796 - accuracy: 0.4316\n",
            "Epoch 1/5\n",
            "314/314 [==============================] - 95s 303ms/step - loss: 1.3726 - accuracy: 0.4323\n",
            "Epoch 2/5\n",
            "314/314 [==============================] - 95s 303ms/step - loss: 1.3662 - accuracy: 0.4343\n",
            "Epoch 3/5\n",
            "314/314 [==============================] - 94s 298ms/step - loss: 1.3603 - accuracy: 0.4388\n",
            "Epoch 4/5\n",
            "314/314 [==============================] - 93s 295ms/step - loss: 1.3549 - accuracy: 0.4388\n",
            "Epoch 5/5\n",
            "314/314 [==============================] - 94s 301ms/step - loss: 1.3498 - accuracy: 0.4436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_finetune_SC.save_weights(\"model_finetune_SC.weights.h5\")"
      ],
      "metadata": {
        "id": "V_fH_KUrDI9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5ca8jpYmnh_8"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h2 style='color:#2c3e50;'><strong>Section 6: Prediction and Evaluation</strong></h2>\n",
        "\n",
        "<hr style=\"border-top: 2px solid #3498db; margin-bottom: 20px; margin-top: 20px;\">\n",
        "\n",
        "<ul style='color:#2c3e50;'>\n",
        "    <li>After finetuning, do <b>prediction</b> task on test data. Then, report <b>f1 score, precision, recall, and accuracy </b> for both datasets.\n",
        "    You can read more about these metrics <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\">here</a>.</li>\n",
        "</ul>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-WNNEdwyUdvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXPZacwonh_8"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Task 6.1: Prediction </strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'> Make prediction on both test datasets.</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoPvO6UJnh_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a1c919-6ff6-48d3-ff76-16fc5a70ac2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 33s 370ms/step\n",
            "4152\n"
          ]
        }
      ],
      "source": [
        "# testing on signal peptide data; save the predicted labels, true labels and sequences to a csv file\n",
        "# fill this cell to create y_pred_SP using the model_finetuned_SP\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "# Create a model with the same architecture as the one used for saving weights\n",
        "# Replace this with your actual model architecture\n",
        "n_classes=2\n",
        "\n",
        "finetune_SP = BERT(vocab_size=vocab_size, embed_size=embed_size, n_layers=n_layers, n_heads=n_heads, max_length=max_length)\n",
        "\n",
        "finetune_SP.load_weights((\"model_finetuned_SP.weights.h5\"))\n",
        "concat_finetune_SP = concat_layers_for_finetuning(finetune_SP)\n",
        "\n",
        "output_layer = Dense(n_classes, activation='sigmoid')(concat_finetune_SP.layers[-1].output[:,0])\n",
        "\n",
        "model = Model(inputs=concat_finetune_SP.input, outputs= output_layer)\n",
        "signalp_test_seq = [tokenize_seq(seq) for seq in signalp_test_data['seq']]\n",
        "signalp_test_seq = np.array(signalp_test_seq)\n",
        "X_test= signalp_test_seq.astype(np.int32)\n",
        "y_pred=model.predict(X_test,batch_size=50)\n",
        "\n",
        "y_pred_SP = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(len(y_pred_SP))\n",
        "\n",
        "\n",
        "# save the predicted labels, true labels and sequences to a csv file\n",
        "signalp_test_data['pred_label'] = y_pred_SP\n",
        "\n",
        "result_df = pd.DataFrame({\n",
        "    'seq': signalp_test_data['seq'],\n",
        "    'label': signalp_test_data['label'],  # Replace with your actual column names\n",
        "    'pred_label': y_pred_SP.tolist()\n",
        "})\n",
        "result_df.to_csv('signalp_pred.csv', index=False)\n",
        "\n",
        "#signalp_test_data.to_csv('signalp_pred.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeDTbmqPnh_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f0ff02-eaac-4289-f93a-4409b55f08cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 32s 389ms/step\n"
          ]
        }
      ],
      "source": [
        "# testing on scop data ; save the predicted labels, true labels and sequences to a csv file\n",
        "# fill this cell to create y_pred_SC using the model_finetuned_SC\n",
        "n_classes=6\n",
        "finetune_SC = BERT(vocab_size=vocab_size, embed_size=embed_size, n_layers=n_layers, n_heads=n_heads, max_length=max_length)\n",
        "\n",
        "finetune_SC.load_weights((\"model_finetuned_SC.weights.h5\"))\n",
        "concat_finetune_SC = concat_layers_for_finetuning(finetune_SC)\n",
        "output_layer = Dense(n_classes, activation='sigmoid')(concat_finetune_SC.layers[-1].output[:,0])\n",
        "model = Model(inputs=concat_finetune_SC.input, outputs= output_layer)\n",
        "\n",
        "scop_test_seq = [tokenize_seq(seq) for seq in scop_test_data['seq']]\n",
        "scop_test_seq = np.array(scop_test_seq)\n",
        "X_test= scop_test_seq.astype(np.int32)\n",
        "\n",
        "y_train = (scop_test_data['label'])\n",
        "label_mapping = {'a': 0, 'b': 1, 'c': 2,'d': 3, 'e': 4, 'f': 5}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_train = y_train.fillna(0)\n",
        "y_train = y_train.astype(int)\n",
        "\n",
        "y_pred=model.predict(X_test,batch_size=50)\n",
        "\n",
        "y_pred_SC = np.argmax(y_pred, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "scop_test_data['pred_label'] = y_pred_SC\n",
        "\n",
        "result_df1 = pd.DataFrame({\n",
        "    'seq': scop_test_data['seq'],\n",
        "    'label': y_train.tolist(),  # Replace with your actual column names\n",
        "    'pred_label': y_pred_SC.tolist()\n",
        "})\n",
        "result_df1.to_csv('scop_pred.csv', index=False)\n",
        "\n",
        "\n",
        "# save the predicted labels, true labels and sequences to a csv file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zkXclAu2nh_8"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Task 6.2: Evaluation</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>Calculate F1 score, precision, recall and accuracy for both test datasets.</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LCj7yTI2nh_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25af7583-19d1-4107-d42d-2f422c35fcd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1623\n",
            "Precision: 0.1623\n",
            "Recall: 1.0000\n",
            "F1-score: 0.2793\n"
          ]
        }
      ],
      "source": [
        "# Fill this cell to evaluate the performance of model_finetuned_SP on signal peptide test data\n",
        "# You can use sklearn library to calculate these metrics.\n",
        "\n",
        "# accuracy\n",
        "# precision\n",
        "# recall\n",
        "# f1-score\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_true) and predicted labels (y_pred) for your test data\n",
        "# Replace y_true and y_pred with your actual data\n",
        "\n",
        "# Calculate accuracy\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your CSV file is named 'your_file.csv'\n",
        "#file_path = '/signalp_pred.csv'  # Adjust the file path accordingly\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('signalp_pred.csv')\n",
        "\n",
        "accuracy = accuracy_score(df.label,df.pred_label)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(df.label,df.pred_label)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(df.label,df.pred_label)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(df.label,df.pred_label)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7nnx0Oonh_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cdbbab-85da-4e2b-fbe2-d2c50b17ce41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2379\n",
            "Precision: 0.0566\n",
            "Recall: 0.2379\n",
            "F1-score: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Fill this cell to evaluate the performance of model_finetuned_SP on signal peptide test data\n",
        "# You can use sklearn library to calculate these metrics.\n",
        "\n",
        "# accuracy\n",
        "# precision\n",
        "# recall\n",
        "# f1-score\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_true) and predicted labels (y_pred) for your test data\n",
        "# Replace y_true and y_pred with your actual data\n",
        "\n",
        "# Calculate accuracy\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your CSV file is named 'your_file.csv'\n",
        "#file_path = '/signalp_pred.csv'  # Adjust the file path accordingly\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df1 = pd.read_csv('scop_pred.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "\n",
        "accuracy = accuracy_score(df1.label,df1.pred_label)\n",
        "# Calculate precision\n",
        "precision = precision_score(df1.label, df1.pred_label, average='weighted')\n",
        "\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(df1.label, df1.pred_label, average='weighted')\n",
        "\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(df1.label, df1.pred_label, average='weighted')\n",
        "\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7Wymo7_Fnh_9"
      },
      "source": [
        "<div style=\"background-color:#f9f9f9; padding:20px; border:1px solid #ddd; border-radius:8px; font-family:Verdana;\">\n",
        "\n",
        "<h3 style='color:#2c3e50;'><strong>Section 7: Experimentation</strong></h3>\n",
        "\n",
        "<p style='color:#2c3e50;'>In the realm of natural language processing, one essential aspect is the reliance on vast datasets for training language models. With limited access to resources like GPUs or memory, we cannot pretrain our own model in this assignment on a huge dataset. Instead, we can use available pretrained models for protein sequences to check if a LLM can improve the performance. In this section of our study, we aim to utilize a pre-trained language model named <b>DistilProtBert</b>, which is accessible through the popular <b>Transformers</b> library.\n",
        "The key objective here is to employ this pre-trained DistilProtBert model and fine-tune it, just as we did in the previous section and compare the performance of the fine-tuned model with and without using pretrained model.\n",
        "Once you have completed the fine-tuning process, it is important to analyze and record any noticeable differences in the model's performance. This entails a comprehensive evaluation of how the fine-tuned model compares to its performance before fine-tuning. You should pay attention to various metrics such as accuracy, precision, recall, and F1-score, among others, to understand the overall impact of the fine-tuning process.\n",
        "In this section, you are free to use any libraries or pretrained models. However, the smallest pretrained model available for preotein sequences is DistilProtBert.\n",
        "</p>\n",
        "<p>\n",
        "You can read more about DistilProtBert <a href=\"https://huggingface.co/yarongef/DistilProtBert\">here</a>.\n",
        "<p> What you need to do in this section is: </p>\n",
        "<p>\n",
        "1. Select one of two finetuning tasks from data directory.</p>\n",
        "<p>\n",
        "2. Finetune DistilProtBert on the selected dataset and report the performance of the model on test data. You need to report <b>f1 score, precision, recall, and accuracy </b>. </p>\n",
        "<p>\n",
        "3. Train your classifier of previous step without using pretrained model (DisilProtBert). Report the performance of the model on test data. You need to report <b>f1 score, precision, recall, and accuracy </b>.\n",
        "</p>\n",
        "<p>\n",
        "4. Compare the performance of the two models and report your findings.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rOioqWkCnh_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650c5293-1c56-44b0-aa4c-a313d395e65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Collecting accelerate>=0.20.3 (from transformers[torch])\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers[torch]\n",
        "%pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertModel, DistilBertTokenizer, \\\n",
        "Trainer, TrainingArguments, DistilBertConfig\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "TRZz9Jnls7P2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lVe8QI7xnh_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "b7bc9191a84744bb9cbd3cddbfa0de95",
            "97a82772cb324e3ea3f3eb78a11e889b",
            "31fc677f8cbb4a38a88d84a55d301370",
            "7f6d27f6dd3a463abc3b93184252b5cb",
            "47a8acf8edc2438b9360e5f046ad7d76",
            "c2d441ec7a914770815f69c20e055185",
            "e4b99beb96a84c4c9e7144addffb0f69",
            "f5027c5fe48346c387c77bde5ffa5d4f",
            "da39e393e1fa4c5b93e4b4d445d1e160",
            "be61b922b43a4703b347f94c449fe018",
            "160a8376364f4f4fa24a0f513fec2ed2",
            "d10cd9029c544f179acf890f372e1fc4",
            "c8be9593ff604c8f804f0a9f4116c5d0",
            "5b55cd90ee5147229b546d1fe829543e",
            "631831a70b754b20b4d6d77b08449336",
            "510933797fd54990bbaed308568d7dab",
            "99f1b8346afe4259a3ce2fa83fea7194",
            "422ae501b98e4c5e955fd54e9e7d36e1",
            "3c281055adcd4f8f85d91503c3c17b85",
            "13a399e07752400b854ea6d9d7b1723c",
            "2bda9d73e9084a359ca0722f01505664",
            "2f583141fa334143a6f84a6388922fe0",
            "9f6342569ded45a0a8e2d0e131e2b1ed",
            "4412771bb1e44619bffd3db4400b2322",
            "63646c9d7e3e40e0b971225eceeaadcd",
            "0fc501f086b44fca8af8d746e118168e",
            "e1f06a2a2d0245f4aa84009a186b89da",
            "62303755818541c09d9fd8d0f3c84a21",
            "2c56a6c90d464a148dfb06d9a5572b3e",
            "123ebd574c8a41a1a22d69e7363d0103",
            "5abe02fa8c494605bb15c753276751b3",
            "1469df79079245ab851e3488f17dd6be",
            "8d2beeb9df2341969efb7fb8a019824b",
            "2279aaef3f31401dad148bf281da7ad0",
            "434ce1a1b3be45739ae6612af4eeb6c7",
            "18d3dc2a39cf4d0bbc9647b1168213e6",
            "0a9d84d587804fb999b2659cc44b1b42",
            "a42ea39bb8e14bedbc3ea930f35d312d",
            "e016381dfbd44f6a9331f689499015a3",
            "6f9e8ffaa84842a68621b349e371dc16",
            "4fb3f45df9b84d98b6c847c769041646",
            "da6672d9f3294ed5a48435c3a6191771",
            "a3928410e22c45d0b8e75284481064f7",
            "55bb187baed940a9bd8671fbbeb09bfb",
            "f330e4f43b31446c88ad527845bc0d33",
            "fd8923aa7d9f471882638030df0035ec",
            "fc1577896693469a80668dce6ec81655",
            "7d6d494e12de4d67bf746965d42075f2",
            "5b5469b7a4e2404695f2249fd572659f",
            "714b5581e7f348e280adb06c23dbae4b",
            "03926920ca0b4a6781db54c76b51f804",
            "958983acb3384215a6adf0f0325c5174",
            "56bfb32ba0cf4e60b1e55bfb79dfda9b",
            "35e258f4f87943e08b89aa1e2fb761b0",
            "8b2f4e2503e142b2ab9946bd1fb92a84"
          ]
        },
        "outputId": "153d4d28-49be-4de4-8dcd-ec86de93ce0f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7bc9191a84744bb9cbd3cddbfa0de95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d10cd9029c544f179acf890f372e1fc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f6342569ded45a0a8e2d0e131e2b1ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/589 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2279aaef3f31401dad148bf281da7ad0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'DistilBertTokenizer'.\n",
            "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/924M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f330e4f43b31446c88ad527845bc0d33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertModel were not initialized from the model checkpoint at yarongef/DistilProtBert and are newly initialized: ['transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.13.attention.q_lin.weight', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.14.output_layer_norm.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.13.attention.k_lin.bias', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.12.attention.out_lin.bias', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.12.attention.k_lin.bias', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.12.sa_layer_norm.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.12.attention.v_lin.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.14.ffn.lin1.weight', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.14.ffn.lin2.weight', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.12.ffn.lin1.weight', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.13.attention.q_lin.bias', 'transformer.layer.12.ffn.lin2.bias', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.13.attention.v_lin.weight', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.13.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.12.attention.v_lin.weight', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.13.sa_layer_norm.weight', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.12.attention.q_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.13.sa_layer_norm.bias', 'transformer.layer.13.output_layer_norm.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.12.output_layer_norm.bias', 'transformer.layer.14.attention.v_lin.bias', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.14.attention.k_lin.bias', 'transformer.layer.2.ffn.lin1.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.4.ffn.lin1.weight', 'embeddings.word_embeddings.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.12.sa_layer_norm.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.13.attention.k_lin.weight', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.12.ffn.lin2.weight', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.12.output_layer_norm.weight', 'transformer.layer.14.ffn.lin1.bias', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.13.ffn.lin1.weight', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.14.attention.out_lin.bias', 'transformer.layer.12.attention.k_lin.weight', 'transformer.layer.14.ffn.lin2.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.12.attention.out_lin.weight', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.14.attention.v_lin.weight', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.13.ffn.lin1.bias', 'transformer.layer.13.ffn.lin2.weight', 'transformer.layer.13.output_layer_norm.weight', 'transformer.layer.14.attention.q_lin.weight', 'transformer.layer.14.attention.q_lin.bias', 'transformer.layer.12.ffn.lin1.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.14.sa_layer_norm.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.10.ffn.lin2.bias', 'embeddings.position_embeddings.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.14.output_layer_norm.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.14.attention.out_lin.weight', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.13.attention.v_lin.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.12.attention.q_lin.weight', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.14.attention.k_lin.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.13.attention.out_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.13.ffn.lin2.bias', 'transformer.layer.14.sa_layer_norm.bias', 'transformer.layer.2.attention.k_lin.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the pretrained model and tokenizer from yarongef/DistilProtBert\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"yarongef/DistilProtBert\", do_lower_case=False)\n",
        "model_distilprotbert = DistilBertModel.from_pretrained(\"yarongef/DistilProtBert\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_distilprotbert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsckMAqejrtC",
        "outputId": "c159cbc7-b412-4904-c09b-b3a129bb3ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertModel(\n",
              "  (embeddings): Embeddings(\n",
              "    (word_embeddings): Embedding(30, 1024, padding_idx=0)\n",
              "    (position_embeddings): Embedding(40000, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (layer): ModuleList(\n",
              "      (0-14): 15 x TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **model_distilprotbert model on Signal-peptide data**"
      ],
      "metadata": {
        "id": "pWYUzzOLuQac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "!pip install torchmetrics\n",
        "\n",
        "import torchmetrics"
      ],
      "metadata": {
        "id": "7N9AHYIt4ohb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9780b467-4dc9-4509-bdd7-7e7c6da43fbf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized = tokenizer(list(signalp_train_data['seq']), max_length=1024, padding=True, truncation=True)\n",
        "train_inputs = torch.tensor(tokenized['input_ids'])\n",
        "train_labels=signalp_train_data['label']\n",
        "label_data = torch.tensor(train_labels)\n",
        "train_dataset = TensorDataset(train_inputs, label_data )\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "asrgX1nC0tpN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer(list(signalp_test_data['seq']), max_length=1024, padding=True, truncation=True)\n",
        "test_inputs = torch.tensor(tokenized['input_ids'])\n",
        "test_labels=signalp_test_data['label']\n",
        "label_data = torch.tensor(test_labels)\n",
        "test_dataset = TensorDataset(test_inputs, label_data )\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "X7nFuKgtuGON"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "optimizer = optim.Adam(  model_distilprotbert.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cvZmqnWA7NCc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training The Distealibert model**"
      ],
      "metadata": {
        "id": "JrrmSOEZf2OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = nn.Linear(1024, 2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_distilprotbert.to(device)\n",
        "for epoch in range(1):\n",
        "    model_distilprotbert.train()\n",
        "    total_loss = 0.0\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_num, (inputs, labels) in enumerate (train_dataloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model_distilprotbert(inputs)\n",
        "\n",
        "        cls_hidden_state = outputs.last_hidden_state[:, 0, :]  # Assuming [CLS] is at index 0\n",
        "        output_dim = model_distilprotbert.config.hidden_size\n",
        "        classification_layer = nn.Linear(output_dim, 2)\n",
        "\n",
        "\n",
        "        # You can now use cls_hidden_state to calculate the logits\n",
        "\n",
        "        logits = classification_layer (cls_hidden_state)\n",
        "\n",
        "        logits = torch.argmax(logits, dim=1).float()\n",
        "\n",
        "        logits.requires_grad = True\n",
        "        loss = criterion(logits.float(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += (logits.float() == labels.float()).sum()\n",
        "\n",
        "    accuracy = 100 * correct / len( train_dataloader.dataset)\n",
        "    loss = running_loss / batch_num\n",
        "    print(f\"Train loss: {loss:.3f}, Train accuracy: {accuracy:.3f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVGClqJa61Ch",
        "outputId": "c8865dbd-bd24-4323-b5be-308dd4b9527f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.000, Train accuracy: 51.048%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test accuracy on Singnal peptide data using the Pretrained Disteli bert model**"
      ],
      "metadata": {
        "id": "nT4g1gKcfVr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric_test = torchmetrics.Accuracy(task='binary')\n",
        "precision_metric_test = torchmetrics.Precision(num_classes=2, average='binary', task='binary')\n",
        "recall_metric_test = torchmetrics.Recall(num_classes=2, average='binary', task='binary')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ... (your previous code)\n",
        "\n",
        "# Assuming you have a test DataLoader named test_dataloader\n",
        "for epoch in range(1):\n",
        "    model_distilprotbert.eval()  # Set the model to evaluation mode\n",
        "    all_labels_test = []\n",
        "    all_logits_test = []\n",
        "\n",
        "    for batch_num, (inputs_test, labels_test) in enumerate(test_dataloader):\n",
        "        inputs_test, labels_test = inputs_test.to(device), labels_test.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs_test = model_distilprotbert(inputs_test)\n",
        "\n",
        "        cls_hidden_state_test = outputs_test.last_hidden_state[:, 0, :]\n",
        "        output_dim_test = model_distilprotbert.config.hidden_size\n",
        "        classification_layer_test = nn.Linear(output_dim_test, 2)\n",
        "\n",
        "        logits_test = classification_layer_test(cls_hidden_state_test)\n",
        "\n",
        "        logits_test = torch.argmax(logits_test, dim=1).float()\n",
        "\n",
        "        all_labels_test.extend(labels_test.cpu().numpy())\n",
        "        all_logits_test.extend(logits_test.cpu().numpy())\n",
        "\n",
        "    # Convert the lists to PyTorch tensors\n",
        "    all_labels_test = torch.tensor(all_labels_test)\n",
        "    all_logits_test = torch.tensor(all_logits_test)\n",
        "\n",
        "\n",
        "    # Calculate precision on test data using torchmetrics\n",
        "    precision_test = precision_metric_test(all_logits_test, all_labels_test)\n",
        "    print(f\"Test precision: {precision_test:.3f}\")\n",
        "    accuracy_test = accuracy_metric_test(all_logits_test, all_labels_test)\n",
        "\n",
        "    print(f\"Test accuracy: {accuracy_test:.3f}\")\n",
        "    recall = recall_metric_test(all_logits_test, all_labels_test)\n",
        "    print(f\"Test recall: {recall:.3f}\")\n",
        "    # F1 Score\n",
        "    f1 = 2 * (precision_test * recall) / (precision_test + recall)\n",
        "\n",
        "    print(\"F1 Score:\", f1.item())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x58jA7zaIKjG",
        "outputId": "3d6160fa-befa-4c8a-fa0f-83989207e127"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test precision: 0.155\n",
            "Test accuracy: 0.513\n",
            "Test recall: 0.448\n",
            "F1 Score: 0.23018291592597961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omKEYdqNdkaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test accuracy on Singnal peptide data without using the Pretrained model**"
      ],
      "metadata": {
        "id": "omZ2asLcdZsV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_V_mRoGdS_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25af7583-19d1-4107-d42d-2f422c35fcd6",
        "id": "bjv3gZBxdTUV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1623\n",
            "Precision: 0.1623\n",
            "Recall: 1.0000\n",
            "F1-score: 0.2793\n"
          ]
        }
      ],
      "source": [
        "# Fill this cell to evaluate the performance of model_finetuned_SP on signal peptide test data\n",
        "# You can use sklearn library to calculate these metrics.\n",
        "\n",
        "# accuracy\n",
        "# precision\n",
        "# recall\n",
        "# f1-score\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_true) and predicted labels (y_pred) for your test data\n",
        "# Replace y_true and y_pred with your actual data\n",
        "\n",
        "# Calculate accuracy\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your CSV file is named 'your_file.csv'\n",
        "#file_path = '/signalp_pred.csv'  # Adjust the file path accordingly\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('signalp_pred.csv')\n",
        "\n",
        "accuracy = accuracy_score(df.label,df.pred_label)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(df.label,df.pred_label)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(df.label,df.pred_label)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(df.label,df.pred_label)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdgtoU05dlNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distelii bert pretrainned model :  Test precision: 0.156\n",
        "# Test accuracy: 0.507\n",
        "# Test recall: 0.464\n",
        "# F1 Score: 0.23410621285438538"
      ],
      "metadata": {
        "id": "lyJ3G_dydlz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without  Distelli bert:\n",
        "# Accuracy: 0.1623\n",
        "# Precision: 0.1623\n",
        "# Recall: 1.0000\n",
        "# F1-score: 0.2793"
      ],
      "metadata": {
        "id": "Muv3bKy_dxVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuVccpvwniAG"
      },
      "outputs": [],
      "source": [
        "# Put your code here for fine-tuning and evaluating DistilProtBert on whichever task you choose\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuiiP3IsniAG"
      },
      "outputs": [],
      "source": [
        "# Put your code here for fine-tuning and evaluating the classifer without pretraining on whichever task you choose\n",
        "\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Yf8lADIniAG"
      },
      "outputs": [],
      "source": [
        "# Write your report here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guX4ylq3niAG"
      },
      "source": [
        "<h2>Submission</h2>\n",
        "\n",
        "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>\n",
        "\n",
        "<p style=\"text-align: justify;\">You need to submit a Jupyter Notebook (*.ipynb) file that contains your completed code and results.\n",
        "<p>\n",
        "Your answers to sections 1-6 will be evaluated based on the correctness of your implementation. Your answer to section 7 will be evaluated based on the correctness of your implementation, the results you report, and the quality of your analysis.\n",
        "\n",
        "<span>The file name should be in <strong>FirstName_LastName</strong> format</span>.</p>\n",
        "<p style=\"text-align: justify;\"><span>DO NOT INCLUDE EXTRA FILES, SUCH AS THE INPUT DATASETS</span>, in your submission;</p>\n",
        "<p style=\"text-align: justify;\">Please download your assignment after submission and make sure it is not corrupted or empty! We will not be responsible for corrupted submissions and will not take a resubmission after the deadline.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaUrKRALniAH"
      },
      "source": [
        "Need Help?\n",
        "If you need help with this assignment, please get in touch with TAs via their emails, or go to their office hours.\n",
        "You are highly encouraged to ask your question on the designated channel for Assignment o on Microsoft Teams (not necessarily monitored by the instructor/TAs). Feel free to help other students with general questions. However, DO NOT share your solution.<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7bc9191a84744bb9cbd3cddbfa0de95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97a82772cb324e3ea3f3eb78a11e889b",
              "IPY_MODEL_31fc677f8cbb4a38a88d84a55d301370",
              "IPY_MODEL_7f6d27f6dd3a463abc3b93184252b5cb"
            ],
            "layout": "IPY_MODEL_47a8acf8edc2438b9360e5f046ad7d76"
          }
        },
        "97a82772cb324e3ea3f3eb78a11e889b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d441ec7a914770815f69c20e055185",
            "placeholder": "​",
            "style": "IPY_MODEL_e4b99beb96a84c4c9e7144addffb0f69",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "31fc677f8cbb4a38a88d84a55d301370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5027c5fe48346c387c77bde5ffa5d4f",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da39e393e1fa4c5b93e4b4d445d1e160",
            "value": 86
          }
        },
        "7f6d27f6dd3a463abc3b93184252b5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be61b922b43a4703b347f94c449fe018",
            "placeholder": "​",
            "style": "IPY_MODEL_160a8376364f4f4fa24a0f513fec2ed2",
            "value": " 86.0/86.0 [00:00&lt;00:00, 2.26kB/s]"
          }
        },
        "47a8acf8edc2438b9360e5f046ad7d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d441ec7a914770815f69c20e055185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4b99beb96a84c4c9e7144addffb0f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5027c5fe48346c387c77bde5ffa5d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da39e393e1fa4c5b93e4b4d445d1e160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be61b922b43a4703b347f94c449fe018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160a8376364f4f4fa24a0f513fec2ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d10cd9029c544f179acf890f372e1fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8be9593ff604c8f804f0a9f4116c5d0",
              "IPY_MODEL_5b55cd90ee5147229b546d1fe829543e",
              "IPY_MODEL_631831a70b754b20b4d6d77b08449336"
            ],
            "layout": "IPY_MODEL_510933797fd54990bbaed308568d7dab"
          }
        },
        "c8be9593ff604c8f804f0a9f4116c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f1b8346afe4259a3ce2fa83fea7194",
            "placeholder": "​",
            "style": "IPY_MODEL_422ae501b98e4c5e955fd54e9e7d36e1",
            "value": "vocab.txt: 100%"
          }
        },
        "5b55cd90ee5147229b546d1fe829543e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c281055adcd4f8f85d91503c3c17b85",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13a399e07752400b854ea6d9d7b1723c",
            "value": 80
          }
        },
        "631831a70b754b20b4d6d77b08449336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bda9d73e9084a359ca0722f01505664",
            "placeholder": "​",
            "style": "IPY_MODEL_2f583141fa334143a6f84a6388922fe0",
            "value": " 80.0/80.0 [00:00&lt;00:00, 2.83kB/s]"
          }
        },
        "510933797fd54990bbaed308568d7dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f1b8346afe4259a3ce2fa83fea7194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422ae501b98e4c5e955fd54e9e7d36e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c281055adcd4f8f85d91503c3c17b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a399e07752400b854ea6d9d7b1723c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bda9d73e9084a359ca0722f01505664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f583141fa334143a6f84a6388922fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6342569ded45a0a8e2d0e131e2b1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4412771bb1e44619bffd3db4400b2322",
              "IPY_MODEL_63646c9d7e3e40e0b971225eceeaadcd",
              "IPY_MODEL_0fc501f086b44fca8af8d746e118168e"
            ],
            "layout": "IPY_MODEL_e1f06a2a2d0245f4aa84009a186b89da"
          }
        },
        "4412771bb1e44619bffd3db4400b2322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62303755818541c09d9fd8d0f3c84a21",
            "placeholder": "​",
            "style": "IPY_MODEL_2c56a6c90d464a148dfb06d9a5572b3e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "63646c9d7e3e40e0b971225eceeaadcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_123ebd574c8a41a1a22d69e7363d0103",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5abe02fa8c494605bb15c753276751b3",
            "value": 112
          }
        },
        "0fc501f086b44fca8af8d746e118168e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1469df79079245ab851e3488f17dd6be",
            "placeholder": "​",
            "style": "IPY_MODEL_8d2beeb9df2341969efb7fb8a019824b",
            "value": " 112/112 [00:00&lt;00:00, 3.74kB/s]"
          }
        },
        "e1f06a2a2d0245f4aa84009a186b89da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62303755818541c09d9fd8d0f3c84a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c56a6c90d464a148dfb06d9a5572b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "123ebd574c8a41a1a22d69e7363d0103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abe02fa8c494605bb15c753276751b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1469df79079245ab851e3488f17dd6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2beeb9df2341969efb7fb8a019824b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2279aaef3f31401dad148bf281da7ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_434ce1a1b3be45739ae6612af4eeb6c7",
              "IPY_MODEL_18d3dc2a39cf4d0bbc9647b1168213e6",
              "IPY_MODEL_0a9d84d587804fb999b2659cc44b1b42"
            ],
            "layout": "IPY_MODEL_a42ea39bb8e14bedbc3ea930f35d312d"
          }
        },
        "434ce1a1b3be45739ae6612af4eeb6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e016381dfbd44f6a9331f689499015a3",
            "placeholder": "​",
            "style": "IPY_MODEL_6f9e8ffaa84842a68621b349e371dc16",
            "value": "config.json: 100%"
          }
        },
        "18d3dc2a39cf4d0bbc9647b1168213e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb3f45df9b84d98b6c847c769041646",
            "max": 589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da6672d9f3294ed5a48435c3a6191771",
            "value": 589
          }
        },
        "0a9d84d587804fb999b2659cc44b1b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3928410e22c45d0b8e75284481064f7",
            "placeholder": "​",
            "style": "IPY_MODEL_55bb187baed940a9bd8671fbbeb09bfb",
            "value": " 589/589 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "a42ea39bb8e14bedbc3ea930f35d312d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e016381dfbd44f6a9331f689499015a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f9e8ffaa84842a68621b349e371dc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fb3f45df9b84d98b6c847c769041646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6672d9f3294ed5a48435c3a6191771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3928410e22c45d0b8e75284481064f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55bb187baed940a9bd8671fbbeb09bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f330e4f43b31446c88ad527845bc0d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd8923aa7d9f471882638030df0035ec",
              "IPY_MODEL_fc1577896693469a80668dce6ec81655",
              "IPY_MODEL_7d6d494e12de4d67bf746965d42075f2"
            ],
            "layout": "IPY_MODEL_5b5469b7a4e2404695f2249fd572659f"
          }
        },
        "fd8923aa7d9f471882638030df0035ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714b5581e7f348e280adb06c23dbae4b",
            "placeholder": "​",
            "style": "IPY_MODEL_03926920ca0b4a6781db54c76b51f804",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "fc1577896693469a80668dce6ec81655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_958983acb3384215a6adf0f0325c5174",
            "max": 924379467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56bfb32ba0cf4e60b1e55bfb79dfda9b",
            "value": 924379467
          }
        },
        "7d6d494e12de4d67bf746965d42075f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e258f4f87943e08b89aa1e2fb761b0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b2f4e2503e142b2ab9946bd1fb92a84",
            "value": " 924M/924M [00:17&lt;00:00, 37.7MB/s]"
          }
        },
        "5b5469b7a4e2404695f2249fd572659f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714b5581e7f348e280adb06c23dbae4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03926920ca0b4a6781db54c76b51f804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "958983acb3384215a6adf0f0325c5174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56bfb32ba0cf4e60b1e55bfb79dfda9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35e258f4f87943e08b89aa1e2fb761b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2f4e2503e142b2ab9946bd1fb92a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}